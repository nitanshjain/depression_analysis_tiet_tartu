{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 22:24:07.125027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, MaxPooling1D, Conv1D, Dropout\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Input, TimeDistributed, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 512)\n",
      "(62,)\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_pickle('/Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/data/x_train.pk')\n",
    "y_train = pd.read_pickle('/Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/data/y_train.pk')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 22:24:14.477488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 512, 16)           64        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512, 16)          64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512, 16)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 256, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 256, 32)           1568      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 128, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 128, 64)           6208      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 64, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 64, 128)           24704     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 32, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32, 32)            20608     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32, 32)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32, 16)            3136      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 16)           64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32, 16)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,953\n",
      "Trainable params: 57,377\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\"\"\"\n",
    "    Default values of Batch Normalization are:\n",
    "        Momentum defaults to 0.99\n",
    "        The hyperparameter ε defaults to 0.001\n",
    "        The hyperparameter β defaults to an all-zeros vector\n",
    "        The hyperparameter γ defaults to an all-ones vector\n",
    "\"\"\"\n",
    "\n",
    "model.add(Conv1D(16, (3), padding='same', activation='relu', input_shape=(x_train.shape[1:])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(Conv1D(32, (3), padding='same', activation='relu', input_shape=(x_train.shape[1:])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(Conv1D(64, (3), padding='same', activation='relu', input_shape=(x_train.shape[1:])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(Conv1D(128, (3), padding='same', activation='relu', input_shape=(x_train.shape[1:])))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), \n",
    "                    bias_regularizer=regularizers.L2(1e-4), \n",
    "                    activity_regularizer=regularizers.L2(1e-5), \n",
    "                    activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9505 - accuracy: 0.4444\n",
      "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to /Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/checkpoints/weights-improvement-BatchNormalization-Dropout-01-0.00.hdf5\n",
      "10/10 [==============================] - 13s 247ms/step - loss: 0.9343 - accuracy: 0.4595 - val_loss: 1.0483 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 1.0226 - accuracy: 0.5278\n",
      "Epoch 2: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 1.1076 - accuracy: 0.5135 - val_loss: 1.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.0713 - accuracy: 0.4324\n",
      "Epoch 3: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 1.0713 - accuracy: 0.4324 - val_loss: 1.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9103 - accuracy: 0.4722\n",
      "Epoch 4: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.9387 - accuracy: 0.4595 - val_loss: 1.2045 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8586 - accuracy: 0.5556\n",
      "Epoch 5: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.8548 - accuracy: 0.5405 - val_loss: 1.1930 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6001 - accuracy: 0.6944\n",
      "Epoch 6: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5875 - accuracy: 0.7027 - val_loss: 1.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8542 - accuracy: 0.5833\n",
      "Epoch 7: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.8526 - accuracy: 0.5676 - val_loss: 1.1211 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7430 - accuracy: 0.6389\n",
      "Epoch 8: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.7526 - accuracy: 0.6216 - val_loss: 1.0612 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7294 - accuracy: 0.6111\n",
      "Epoch 9: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.7276 - accuracy: 0.6216 - val_loss: 1.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8274 - accuracy: 0.5556\n",
      "Epoch 10: val_accuracy did not improve from 0.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.8109 - accuracy: 0.5676 - val_loss: 0.9490 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.5405\n",
      "Epoch 11: val_accuracy improved from 0.00000 to 0.16000, saving model to /Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/checkpoints/weights-improvement-BatchNormalization-Dropout-11-0.16.hdf5\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.7145 - accuracy: 0.5405 - val_loss: 0.7894 - val_accuracy: 0.1600\n",
      "Epoch 12/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8372 - accuracy: 0.5833\n",
      "Epoch 12: val_accuracy improved from 0.16000 to 0.88000, saving model to /Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/checkpoints/weights-improvement-BatchNormalization-Dropout-12-0.88.hdf5\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.8326 - accuracy: 0.5946 - val_loss: 0.5794 - val_accuracy: 0.8800\n",
      "Epoch 13/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8138 - accuracy: 0.5556\n",
      "Epoch 13: val_accuracy improved from 0.88000 to 1.00000, saving model to /Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/checkpoints/weights-improvement-BatchNormalization-Dropout-13-1.00.hdf5\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.7985 - accuracy: 0.5676 - val_loss: 0.4403 - val_accuracy: 1.0000\n",
      "Epoch 14/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8893 - accuracy: 0.4722\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.9828 - accuracy: 0.4595 - val_loss: 0.3487 - val_accuracy: 1.0000\n",
      "Epoch 15/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6713 - accuracy: 0.6389\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6902 - accuracy: 0.6216 - val_loss: 0.2899 - val_accuracy: 1.0000\n",
      "Epoch 16/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9270 - accuracy: 0.4444\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.9109 - accuracy: 0.4595 - val_loss: 0.2371 - val_accuracy: 1.0000\n",
      "Epoch 17/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6120 - accuracy: 0.6944\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.6042 - accuracy: 0.7027 - val_loss: 0.2089 - val_accuracy: 1.0000\n",
      "Epoch 18/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.0888 - accuracy: 0.4595\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 1.0888 - accuracy: 0.4595 - val_loss: 0.2453 - val_accuracy: 1.0000\n",
      "Epoch 19/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9458 - accuracy: 0.5000\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.9234 - accuracy: 0.5135 - val_loss: 0.2243 - val_accuracy: 1.0000\n",
      "Epoch 20/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7612 - accuracy: 0.4722\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.7451 - accuracy: 0.4865 - val_loss: 0.2299 - val_accuracy: 1.0000\n",
      "Epoch 21/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7899 - accuracy: 0.6667\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.7705 - accuracy: 0.6757 - val_loss: 0.2201 - val_accuracy: 1.0000\n",
      "Epoch 22/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7331 - accuracy: 0.5000\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.7152 - accuracy: 0.5135 - val_loss: 0.2044 - val_accuracy: 1.0000\n",
      "Epoch 23/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8800 - accuracy: 0.4167\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.8627 - accuracy: 0.4324 - val_loss: 0.1805 - val_accuracy: 1.0000\n",
      "Epoch 24/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7632 - accuracy: 0.5833\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.7503 - accuracy: 0.5946 - val_loss: 0.1679 - val_accuracy: 1.0000\n",
      "Epoch 25/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6669 - accuracy: 0.5556\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6712 - accuracy: 0.5405 - val_loss: 0.1687 - val_accuracy: 1.0000\n",
      "Epoch 26/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9948 - accuracy: 0.4444\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 1.0483 - accuracy: 0.4324 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
      "Epoch 27/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4834 - accuracy: 0.7500\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5081 - accuracy: 0.7297 - val_loss: 0.1260 - val_accuracy: 1.0000\n",
      "Epoch 28/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.5676\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.7631 - accuracy: 0.5676 - val_loss: 0.0914 - val_accuracy: 1.0000\n",
      "Epoch 29/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8558 - accuracy: 0.5556\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.8404 - accuracy: 0.5676 - val_loss: 0.1249 - val_accuracy: 1.0000\n",
      "Epoch 30/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9331 - accuracy: 0.3333\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.9760 - accuracy: 0.3243 - val_loss: 0.1798 - val_accuracy: 1.0000\n",
      "Epoch 31/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8067 - accuracy: 0.6111\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.7924 - accuracy: 0.6216 - val_loss: 0.1588 - val_accuracy: 1.0000\n",
      "Epoch 32/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6154 - accuracy: 0.6944\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.6296 - accuracy: 0.6757 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 33/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7353 - accuracy: 0.5000\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.7271 - accuracy: 0.5135 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
      "Epoch 34/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8343 - accuracy: 0.5833\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.8126 - accuracy: 0.5946 - val_loss: 0.2225 - val_accuracy: 0.9600\n",
      "Epoch 35/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5806 - accuracy: 0.6111\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5928 - accuracy: 0.5946 - val_loss: 0.2342 - val_accuracy: 0.9600\n",
      "Epoch 36/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.5405\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.7743 - accuracy: 0.5405 - val_loss: 0.3073 - val_accuracy: 0.9600\n",
      "Epoch 37/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5709 - accuracy: 0.7500\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5642 - accuracy: 0.7568 - val_loss: 0.2810 - val_accuracy: 0.9600\n",
      "Epoch 38/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7336 - accuracy: 0.6389\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.7327 - accuracy: 0.6216 - val_loss: 0.3487 - val_accuracy: 0.9200\n",
      "Epoch 39/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8933 - accuracy: 0.4722\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.8712 - accuracy: 0.4865 - val_loss: 0.4617 - val_accuracy: 0.8400\n",
      "Epoch 40/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6673 - accuracy: 0.6389\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6788 - accuracy: 0.6216 - val_loss: 0.6449 - val_accuracy: 0.6000\n",
      "Epoch 41/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5877 - accuracy: 0.6389\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5726 - accuracy: 0.6486 - val_loss: 0.6164 - val_accuracy: 0.6400\n",
      "Epoch 42/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8002 - accuracy: 0.6111\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.7798 - accuracy: 0.6216 - val_loss: 0.4886 - val_accuracy: 0.7600\n",
      "Epoch 43/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6882 - accuracy: 0.6111\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6717 - accuracy: 0.6216 - val_loss: 0.3449 - val_accuracy: 0.9600\n",
      "Epoch 44/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5681 - accuracy: 0.7222\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5740 - accuracy: 0.7027 - val_loss: 0.2938 - val_accuracy: 0.9600\n",
      "Epoch 45/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6012 - accuracy: 0.6944\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6296 - accuracy: 0.6757 - val_loss: 0.2979 - val_accuracy: 0.9600\n",
      "Epoch 46/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.5946\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.7102 - accuracy: 0.5946 - val_loss: 0.2367 - val_accuracy: 0.9600\n",
      "Epoch 47/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6085 - accuracy: 0.6667\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.6009 - accuracy: 0.6757 - val_loss: 0.2071 - val_accuracy: 0.9600\n",
      "Epoch 48/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6799 - accuracy: 0.6111\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6722 - accuracy: 0.6216 - val_loss: 0.3249 - val_accuracy: 0.8400\n",
      "Epoch 49/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.9347 - accuracy: 0.5000\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.9374 - accuracy: 0.4865 - val_loss: 0.5686 - val_accuracy: 0.7200\n",
      "Epoch 50/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5355 - accuracy: 0.7222\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5278 - accuracy: 0.7297 - val_loss: 0.4657 - val_accuracy: 0.7200\n",
      "Epoch 51/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5958 - accuracy: 0.6944\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.6067 - accuracy: 0.6757 - val_loss: 0.3816 - val_accuracy: 0.8400\n",
      "Epoch 52/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7163 - accuracy: 0.5556\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.7200 - accuracy: 0.5405 - val_loss: 0.3817 - val_accuracy: 0.8400\n",
      "Epoch 53/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5740 - accuracy: 0.7778\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5876 - accuracy: 0.7568 - val_loss: 0.2923 - val_accuracy: 0.8800\n",
      "Epoch 54/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5668 - accuracy: 0.6667\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.5569 - accuracy: 0.6757 - val_loss: 0.1691 - val_accuracy: 1.0000\n",
      "Epoch 55/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7838\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.5417 - accuracy: 0.7838 - val_loss: 0.1626 - val_accuracy: 1.0000\n",
      "Epoch 56/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5770 - accuracy: 0.6944\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.5636 - accuracy: 0.7027 - val_loss: 0.1551 - val_accuracy: 1.0000\n",
      "Epoch 57/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5787 - accuracy: 0.6389\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5660 - accuracy: 0.6486 - val_loss: 0.2232 - val_accuracy: 0.9600\n",
      "Epoch 58/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6183 - accuracy: 0.6667\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.6068 - accuracy: 0.6757 - val_loss: 0.2323 - val_accuracy: 0.9600\n",
      "Epoch 59/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7738 - accuracy: 0.5833\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.7613 - accuracy: 0.5946 - val_loss: 0.2947 - val_accuracy: 0.8800\n",
      "Epoch 60/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5384 - accuracy: 0.7500\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5650 - accuracy: 0.7297 - val_loss: 0.2884 - val_accuracy: 0.9200\n",
      "Epoch 61/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6515 - accuracy: 0.6667\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.7010 - accuracy: 0.6486 - val_loss: 0.2327 - val_accuracy: 0.9600\n",
      "Epoch 62/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5767 - accuracy: 0.6667\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.5630 - accuracy: 0.6757 - val_loss: 0.1499 - val_accuracy: 0.9600\n",
      "Epoch 63/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.6757\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.6748 - accuracy: 0.6757 - val_loss: 0.2029 - val_accuracy: 0.9600\n",
      "Epoch 64/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4231 - accuracy: 0.8611\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.4223 - accuracy: 0.8649 - val_loss: 0.2595 - val_accuracy: 0.8800\n",
      "Epoch 65/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5787 - accuracy: 0.6944\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.6255 - accuracy: 0.6757 - val_loss: 0.2079 - val_accuracy: 0.9200\n",
      "Epoch 66/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5865 - accuracy: 0.7222\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.6025 - accuracy: 0.7027 - val_loss: 0.1471 - val_accuracy: 0.9600\n",
      "Epoch 67/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4414 - accuracy: 0.8611\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.4633 - accuracy: 0.8378 - val_loss: 0.2341 - val_accuracy: 0.8800\n",
      "Epoch 68/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5995 - accuracy: 0.6944\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.6000 - accuracy: 0.7027 - val_loss: 0.3905 - val_accuracy: 0.8400\n",
      "Epoch 69/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.8301 - accuracy: 0.5278\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.8122 - accuracy: 0.5405 - val_loss: 0.2680 - val_accuracy: 0.8400\n",
      "Epoch 70/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.7568\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.4629 - accuracy: 0.7568 - val_loss: 0.2603 - val_accuracy: 0.8400\n",
      "Epoch 71/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5733 - accuracy: 0.6944\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.5664 - accuracy: 0.7027 - val_loss: 0.2839 - val_accuracy: 0.8400\n",
      "Epoch 72/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5416 - accuracy: 0.7222\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.5275 - accuracy: 0.7297 - val_loss: 0.2939 - val_accuracy: 0.8400\n",
      "Epoch 73/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6502 - accuracy: 0.6667\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.6659 - accuracy: 0.6486 - val_loss: 0.2935 - val_accuracy: 0.8400\n",
      "Epoch 74/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6322 - accuracy: 0.7500\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.6247 - accuracy: 0.7568 - val_loss: 0.2442 - val_accuracy: 0.9200\n",
      "Epoch 75/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5774 - accuracy: 0.6944\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.5694 - accuracy: 0.7027 - val_loss: 0.1618 - val_accuracy: 1.0000\n",
      "Epoch 76/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6627 - accuracy: 0.6111\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.6474 - accuracy: 0.6216 - val_loss: 0.2092 - val_accuracy: 0.9600\n",
      "Epoch 77/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7337 - accuracy: 0.6216\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.7337 - accuracy: 0.6216 - val_loss: 0.2568 - val_accuracy: 0.9200\n",
      "Epoch 78/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5622 - accuracy: 0.6389\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5780 - accuracy: 0.6216 - val_loss: 0.2729 - val_accuracy: 0.8800\n",
      "Epoch 79/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6857 - accuracy: 0.5833\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.6733 - accuracy: 0.5946 - val_loss: 0.3538 - val_accuracy: 0.8000\n",
      "Epoch 80/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4786 - accuracy: 0.8333\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.4694 - accuracy: 0.8378 - val_loss: 0.3087 - val_accuracy: 0.8400\n",
      "Epoch 81/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5504 - accuracy: 0.6389\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5625 - accuracy: 0.6216 - val_loss: 0.3155 - val_accuracy: 0.8400\n",
      "Epoch 82/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6679 - accuracy: 0.6111\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.6631 - accuracy: 0.6216 - val_loss: 0.2855 - val_accuracy: 0.8400\n",
      "Epoch 83/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4267 - accuracy: 0.8333\n",
      "Epoch 83: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.4206 - accuracy: 0.8378 - val_loss: 0.4072 - val_accuracy: 0.8000\n",
      "Epoch 84/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5222 - accuracy: 0.8056\n",
      "Epoch 84: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.5127 - accuracy: 0.8108 - val_loss: 0.3991 - val_accuracy: 0.8000\n",
      "Epoch 85/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4466 - accuracy: 0.8056\n",
      "Epoch 85: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.4366 - accuracy: 0.8108 - val_loss: 0.3463 - val_accuracy: 0.8400\n",
      "Epoch 86/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6059 - accuracy: 0.7778\n",
      "Epoch 86: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.5909 - accuracy: 0.7838 - val_loss: 0.2946 - val_accuracy: 0.8400\n",
      "Epoch 87/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6227 - accuracy: 0.6389\n",
      "Epoch 87: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.6376 - accuracy: 0.6216 - val_loss: 0.2907 - val_accuracy: 0.8400\n",
      "Epoch 88/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5288 - accuracy: 0.6944\n",
      "Epoch 88: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.5658 - accuracy: 0.6757 - val_loss: 0.1743 - val_accuracy: 0.9600\n",
      "Epoch 89/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6066 - accuracy: 0.7778\n",
      "Epoch 89: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.6340 - accuracy: 0.7568 - val_loss: 0.4271 - val_accuracy: 0.8000\n",
      "Epoch 90/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6392 - accuracy: 0.6667\n",
      "Epoch 90: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.6247 - accuracy: 0.6757 - val_loss: 0.3611 - val_accuracy: 0.8000\n",
      "Epoch 91/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4780 - accuracy: 0.7778\n",
      "Epoch 91: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.4877 - accuracy: 0.7568 - val_loss: 0.4137 - val_accuracy: 0.8000\n",
      "Epoch 92/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4690 - accuracy: 0.7500\n",
      "Epoch 92: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.4651 - accuracy: 0.7568 - val_loss: 0.4145 - val_accuracy: 0.8000\n",
      "Epoch 93/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5974 - accuracy: 0.6667\n",
      "Epoch 93: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5817 - accuracy: 0.6757 - val_loss: 0.3646 - val_accuracy: 0.8000\n",
      "Epoch 94/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5853 - accuracy: 0.6944\n",
      "Epoch 94: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.5705 - accuracy: 0.7027 - val_loss: 0.3199 - val_accuracy: 0.8000\n",
      "Epoch 95/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.7498 - accuracy: 0.6389\n",
      "Epoch 95: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.7384 - accuracy: 0.6486 - val_loss: 0.3168 - val_accuracy: 0.8400\n",
      "Epoch 96/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4917 - accuracy: 0.7500\n",
      "Epoch 96: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 0.5234 - accuracy: 0.7297 - val_loss: 0.4473 - val_accuracy: 0.8000\n",
      "Epoch 97/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5420 - accuracy: 0.7500\n",
      "Epoch 97: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.5319 - accuracy: 0.7568 - val_loss: 0.4437 - val_accuracy: 0.8000\n",
      "Epoch 98/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4822 - accuracy: 0.7778\n",
      "Epoch 98: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.4906 - accuracy: 0.7568 - val_loss: 0.4656 - val_accuracy: 0.7600\n",
      "Epoch 99/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4623 - accuracy: 0.7222\n",
      "Epoch 99: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.4545 - accuracy: 0.7297 - val_loss: 0.6923 - val_accuracy: 0.6800\n",
      "Epoch 100/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5333 - accuracy: 0.7222\n",
      "Epoch 100: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.5228 - accuracy: 0.7297 - val_loss: 0.6703 - val_accuracy: 0.6800\n",
      "Epoch 101/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6498 - accuracy: 0.7500\n",
      "Epoch 101: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.6370 - accuracy: 0.7568 - val_loss: 0.4125 - val_accuracy: 0.8000\n",
      "Epoch 102/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.6486\n",
      "Epoch 102: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.5581 - accuracy: 0.6486 - val_loss: 0.4282 - val_accuracy: 0.8000\n",
      "Epoch 103/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.7838\n",
      "Epoch 103: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 0.3476 - accuracy: 0.7838 - val_loss: 0.5046 - val_accuracy: 0.7600\n",
      "Epoch 104/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7297\n",
      "Epoch 104: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.5637 - accuracy: 0.7297 - val_loss: 0.8865 - val_accuracy: 0.5200\n",
      "Epoch 105/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3551 - accuracy: 0.8333\n",
      "Epoch 105: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3756 - accuracy: 0.8108 - val_loss: 0.8312 - val_accuracy: 0.6000\n",
      "Epoch 106/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6035 - accuracy: 0.6667\n",
      "Epoch 106: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.6124 - accuracy: 0.6486 - val_loss: 0.5221 - val_accuracy: 0.7600\n",
      "Epoch 107/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6293 - accuracy: 0.6667\n",
      "Epoch 107: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.6284 - accuracy: 0.6757 - val_loss: 0.6556 - val_accuracy: 0.7200\n",
      "Epoch 108/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3874 - accuracy: 0.7297\n",
      "Epoch 108: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.3874 - accuracy: 0.7297 - val_loss: 0.5518 - val_accuracy: 0.8000\n",
      "Epoch 109/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5215 - accuracy: 0.7500\n",
      "Epoch 109: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5083 - accuracy: 0.7568 - val_loss: 0.3438 - val_accuracy: 0.8000\n",
      "Epoch 110/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.6757\n",
      "Epoch 110: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5517 - accuracy: 0.6757 - val_loss: 0.3645 - val_accuracy: 0.8000\n",
      "Epoch 111/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5175 - accuracy: 0.6389\n",
      "Epoch 111: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5178 - accuracy: 0.6486 - val_loss: 0.3788 - val_accuracy: 0.8000\n",
      "Epoch 112/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5418 - accuracy: 0.7500\n",
      "Epoch 112: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5327 - accuracy: 0.7568 - val_loss: 0.4067 - val_accuracy: 0.8000\n",
      "Epoch 113/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4674 - accuracy: 0.7500\n",
      "Epoch 113: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.4639 - accuracy: 0.7568 - val_loss: 0.6136 - val_accuracy: 0.8000\n",
      "Epoch 114/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4645 - accuracy: 0.7778\n",
      "Epoch 114: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.4848 - accuracy: 0.7568 - val_loss: 0.5616 - val_accuracy: 0.8000\n",
      "Epoch 115/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.6460 - accuracy: 0.6667\n",
      "Epoch 115: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.6292 - accuracy: 0.6757 - val_loss: 0.5098 - val_accuracy: 0.8000\n",
      "Epoch 116/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5450 - accuracy: 0.7222\n",
      "Epoch 116: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5640 - accuracy: 0.7027 - val_loss: 0.6034 - val_accuracy: 0.7600\n",
      "Epoch 117/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4744 - accuracy: 0.7222\n",
      "Epoch 117: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.4678 - accuracy: 0.7297 - val_loss: 0.7654 - val_accuracy: 0.6800\n",
      "Epoch 118/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5770 - accuracy: 0.6389\n",
      "Epoch 118: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.5804 - accuracy: 0.6216 - val_loss: 0.7270 - val_accuracy: 0.7200\n",
      "Epoch 119/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.6757\n",
      "Epoch 119: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5912 - accuracy: 0.6757 - val_loss: 0.6986 - val_accuracy: 0.7200\n",
      "Epoch 120/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4989 - accuracy: 0.7222\n",
      "Epoch 120: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.4908 - accuracy: 0.7297 - val_loss: 0.4723 - val_accuracy: 0.8000\n",
      "Epoch 121/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5453 - accuracy: 0.7778\n",
      "Epoch 121: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5313 - accuracy: 0.7838 - val_loss: 0.4921 - val_accuracy: 0.8000\n",
      "Epoch 122/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4795 - accuracy: 0.8056\n",
      "Epoch 122: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4689 - accuracy: 0.8108 - val_loss: 0.6310 - val_accuracy: 0.7600\n",
      "Epoch 123/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5011 - accuracy: 0.7222\n",
      "Epoch 123: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5059 - accuracy: 0.7297 - val_loss: 0.9414 - val_accuracy: 0.6400\n",
      "Epoch 124/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5406 - accuracy: 0.6389\n",
      "Epoch 124: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.5536 - accuracy: 0.6216 - val_loss: 0.9042 - val_accuracy: 0.6400\n",
      "Epoch 125/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4699 - accuracy: 0.8333\n",
      "Epoch 125: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4632 - accuracy: 0.8378 - val_loss: 0.4220 - val_accuracy: 0.8000\n",
      "Epoch 126/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4748 - accuracy: 0.7778\n",
      "Epoch 126: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.4640 - accuracy: 0.7838 - val_loss: 0.3987 - val_accuracy: 0.8400\n",
      "Epoch 127/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5410 - accuracy: 0.7778\n",
      "Epoch 127: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5378 - accuracy: 0.7838 - val_loss: 0.5899 - val_accuracy: 0.8000\n",
      "Epoch 128/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4285 - accuracy: 0.8056\n",
      "Epoch 128: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4901 - accuracy: 0.7838 - val_loss: 0.5569 - val_accuracy: 0.8000\n",
      "Epoch 129/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4313 - accuracy: 0.8333\n",
      "Epoch 129: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.4429 - accuracy: 0.8108 - val_loss: 0.3595 - val_accuracy: 0.8400\n",
      "Epoch 130/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4599 - accuracy: 0.6667\n",
      "Epoch 130: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4498 - accuracy: 0.6757 - val_loss: 0.5389 - val_accuracy: 0.8000\n",
      "Epoch 131/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4239 - accuracy: 0.8056\n",
      "Epoch 131: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.6763 - val_accuracy: 0.7600\n",
      "Epoch 132/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5713 - accuracy: 0.7778\n",
      "Epoch 132: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5564 - accuracy: 0.7838 - val_loss: 0.6097 - val_accuracy: 0.8000\n",
      "Epoch 133/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3997 - accuracy: 0.8333\n",
      "Epoch 133: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.4352 - val_accuracy: 0.8000\n",
      "Epoch 134/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.7568\n",
      "Epoch 134: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.4983 - accuracy: 0.7568 - val_loss: 0.6569 - val_accuracy: 0.7600\n",
      "Epoch 135/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5616 - accuracy: 0.7778\n",
      "Epoch 135: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5530 - accuracy: 0.7838 - val_loss: 0.8523 - val_accuracy: 0.6800\n",
      "Epoch 136/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5233 - accuracy: 0.7778\n",
      "Epoch 136: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.5242 - accuracy: 0.7838 - val_loss: 0.7048 - val_accuracy: 0.6800\n",
      "Epoch 137/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3353 - accuracy: 0.8056\n",
      "Epoch 137: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.3311 - accuracy: 0.8108 - val_loss: 0.7671 - val_accuracy: 0.6800\n",
      "Epoch 138/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3428 - accuracy: 0.8611\n",
      "Epoch 138: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.3404 - accuracy: 0.8649 - val_loss: 0.6066 - val_accuracy: 0.7600\n",
      "Epoch 139/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4679 - accuracy: 0.8611\n",
      "Epoch 139: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.4855 - accuracy: 0.8378 - val_loss: 0.5655 - val_accuracy: 0.7600\n",
      "Epoch 140/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4032 - accuracy: 0.8056\n",
      "Epoch 140: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.8520 - val_accuracy: 0.6400\n",
      "Epoch 141/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3445 - accuracy: 0.8611\n",
      "Epoch 141: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4109 - accuracy: 0.8378 - val_loss: 0.8045 - val_accuracy: 0.6800\n",
      "Epoch 142/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5948 - accuracy: 0.6667\n",
      "Epoch 142: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.5846 - accuracy: 0.6757 - val_loss: 0.2758 - val_accuracy: 0.8400\n",
      "Epoch 143/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3490 - accuracy: 0.8333\n",
      "Epoch 143: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3559 - accuracy: 0.8378 - val_loss: 0.4004 - val_accuracy: 0.8000\n",
      "Epoch 144/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4262 - accuracy: 0.8611\n",
      "Epoch 144: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.4275 - accuracy: 0.8649 - val_loss: 0.6699 - val_accuracy: 0.7200\n",
      "Epoch 145/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4540 - accuracy: 0.8056\n",
      "Epoch 145: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.4426 - accuracy: 0.8108 - val_loss: 0.7549 - val_accuracy: 0.6800\n",
      "Epoch 146/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3581 - accuracy: 0.8333\n",
      "Epoch 146: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3656 - accuracy: 0.8378 - val_loss: 0.7144 - val_accuracy: 0.7600\n",
      "Epoch 147/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4836 - accuracy: 0.7500\n",
      "Epoch 147: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4817 - accuracy: 0.7568 - val_loss: 0.8413 - val_accuracy: 0.6400\n",
      "Epoch 148/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3286 - accuracy: 0.8889\n",
      "Epoch 148: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3625 - accuracy: 0.8649 - val_loss: 0.6196 - val_accuracy: 0.8000\n",
      "Epoch 149/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4139 - accuracy: 0.8056\n",
      "Epoch 149: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.4227 - accuracy: 0.7838 - val_loss: 0.5226 - val_accuracy: 0.8000\n",
      "Epoch 150/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4560 - accuracy: 0.7222\n",
      "Epoch 150: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.4447 - accuracy: 0.7297 - val_loss: 0.6165 - val_accuracy: 0.8000\n",
      "Epoch 151/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4296 - accuracy: 0.8333\n",
      "Epoch 151: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.4328 - accuracy: 0.8378 - val_loss: 0.5086 - val_accuracy: 0.8000\n",
      "Epoch 152/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3376 - accuracy: 0.8889\n",
      "Epoch 152: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3479 - accuracy: 0.8649 - val_loss: 0.5927 - val_accuracy: 0.8000\n",
      "Epoch 153/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3469 - accuracy: 0.8611\n",
      "Epoch 153: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3378 - accuracy: 0.8649 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 154/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4327 - accuracy: 0.7778\n",
      "Epoch 154: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.4225 - accuracy: 0.7838 - val_loss: 0.5070 - val_accuracy: 0.8000\n",
      "Epoch 155/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.7297\n",
      "Epoch 155: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.4611 - accuracy: 0.7297 - val_loss: 0.4762 - val_accuracy: 0.8000\n",
      "Epoch 156/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3963 - accuracy: 0.7778\n",
      "Epoch 156: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3879 - accuracy: 0.7838 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
      "Epoch 157/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3959 - accuracy: 0.8611\n",
      "Epoch 157: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3854 - accuracy: 0.8649 - val_loss: 0.5864 - val_accuracy: 0.7600\n",
      "Epoch 158/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3715 - accuracy: 0.8611\n",
      "Epoch 158: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.3683 - accuracy: 0.8649 - val_loss: 0.8455 - val_accuracy: 0.5600\n",
      "Epoch 159/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.7297\n",
      "Epoch 159: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.4726 - accuracy: 0.7297 - val_loss: 0.7355 - val_accuracy: 0.6400\n",
      "Epoch 160/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3720 - accuracy: 0.7500\n",
      "Epoch 160: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3653 - accuracy: 0.7568 - val_loss: 0.6868 - val_accuracy: 0.6800\n",
      "Epoch 161/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3288 - accuracy: 0.9444\n",
      "Epoch 161: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3323 - accuracy: 0.9459 - val_loss: 0.7183 - val_accuracy: 0.6400\n",
      "Epoch 162/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3306 - accuracy: 0.9167\n",
      "Epoch 162: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.3230 - accuracy: 0.9189 - val_loss: 0.6779 - val_accuracy: 0.6400\n",
      "Epoch 163/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4237 - accuracy: 0.8333\n",
      "Epoch 163: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.4150 - accuracy: 0.8378 - val_loss: 0.6764 - val_accuracy: 0.6400\n",
      "Epoch 164/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.5878 - accuracy: 0.7500\n",
      "Epoch 164: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.6345 - accuracy: 0.7297 - val_loss: 0.5954 - val_accuracy: 0.7600\n",
      "Epoch 165/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3563 - accuracy: 0.8889\n",
      "Epoch 165: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.4133 - accuracy: 0.8649 - val_loss: 0.2974 - val_accuracy: 0.8800\n",
      "Epoch 166/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.7838\n",
      "Epoch 166: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.4724 - accuracy: 0.7838 - val_loss: 0.4307 - val_accuracy: 0.8000\n",
      "Epoch 167/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4808 - accuracy: 0.7778\n",
      "Epoch 167: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.5553 - accuracy: 0.7568 - val_loss: 0.7486 - val_accuracy: 0.6400\n",
      "Epoch 168/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2877 - accuracy: 0.8611\n",
      "Epoch 168: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2811 - accuracy: 0.8649 - val_loss: 0.6323 - val_accuracy: 0.7200\n",
      "Epoch 169/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3631 - accuracy: 0.8611\n",
      "Epoch 169: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.3994 - accuracy: 0.8378 - val_loss: 0.4843 - val_accuracy: 0.8000\n",
      "Epoch 170/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3861 - accuracy: 0.8333\n",
      "Epoch 170: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.3759 - accuracy: 0.8378 - val_loss: 0.7243 - val_accuracy: 0.6000\n",
      "Epoch 171/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3370 - accuracy: 0.8333\n",
      "Epoch 171: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.3371 - accuracy: 0.8378 - val_loss: 0.7771 - val_accuracy: 0.5600\n",
      "Epoch 172/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.8649\n",
      "Epoch 172: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.3772 - accuracy: 0.8649 - val_loss: 0.6235 - val_accuracy: 0.6800\n",
      "Epoch 173/175\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8378\n",
      "Epoch 173: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.3707 - accuracy: 0.8378 - val_loss: 0.3945 - val_accuracy: 0.8000\n",
      "Epoch 174/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3514 - accuracy: 0.8611\n",
      "Epoch 174: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.3454 - accuracy: 0.8649 - val_loss: 0.3651 - val_accuracy: 0.8400\n",
      "Epoch 175/175\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4395 - accuracy: 0.8333\n",
      "Epoch 175: val_accuracy did not improve from 1.00000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.4285 - accuracy: 0.8378 - val_loss: 0.3336 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1324aafe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "checkpoint_filepath = '/Users/nitanshjain/Documents/Projects/Depression_Analysis/AVEC_DAIC_WOZ_2017/checkpoints/weights-improvement-BatchNormalization-Dropout-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=175,\n",
    "            callbacks=[model_checkpoint_callback],\n",
    "            validation_split=0.4,\n",
    "            shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, (3), padding='same', activation='relu', input_shape=(x_train_input_shape[1], x_train_input_shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=(2), padding='same'))\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "Epoch 15/20\n",
    "6/6 [==============================] - 315s 52s/step - loss: 0.5692 - accuracy: 0.7178 - val_loss: 0.6434 - val_accuracy: 0.7857"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
